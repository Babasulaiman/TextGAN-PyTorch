====================================================================================================
> training arguments:
>>> if_test: False
>>> run_model: relgan
>>> k_label: 2
>>> dataset: sample
>>> model_type: vanilla
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: True
>>> cuda: True
>>> device: 0
>>> devices: 0
>>> shuffle: False
>>> gen_init: normal
>>> dis_init: uniform
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 18
>>> vocab_size: 478
>>> mle_epoch: 5
>>> clas_pre_epoch: 10
>>> adv_epoch: 10
>>> inter_epoch: 15
>>> batch_size: 4
>>> max_seq_len: 115
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.0001
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 20
>>> train_data: dataset/sample.txt
>>> test_data: dataset/testdata/sample_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: False
>>> gen_pretrain: False
>>> dis_pretrain: False
>>> adv_g_step: 1
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 5
>>> adv_d_epoch: 3
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> use_nll_oracle: False
>>> use_nll_gen: True
>>> use_nll_div: True
>>> use_bleu: True
>>> use_self_bleu: False
>>> use_clas_acc: True
>>> use_ppl: False
>>> log_file: log/log_0920_0432_57.txt
>>> save_root: save/20240920/sample/relgan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl115_temp1_lfd0.0_T0920_0432_57/
>>> signal_file: run_signal.txt
>>> tips: 
====================================================================================================
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : pre_loss = 33.2940, BLEU-[2, 3, 4, 5] = [0.006, 0.003, 0.003, 0.003], NLL_gen = 7.7841, NLL_div = 0.2914, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 4 : pre_loss = 3.0058, BLEU-[2, 3, 4, 5] = [0.076, 0.023, 0.014, 0.01], NLL_gen = 2.7486, NLL_div = 1.1649, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
Starting Adversarial Training...
[ADV] epoch 0: g_loss: 0.6930, d_loss: 0.6929, BLEU-[2, 3, 4, 5] = [0.066, 0.023, 0.014, 0.011], NLL_gen = 2.7495, NLL_div = 1.078, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
[ADV] epoch 9: g_loss: 0.7119, d_loss: 0.6746, BLEU-[2, 3, 4, 5] = [0.062, 0.023, 0.015, 0.012], NLL_gen = 2.7442, NLL_div = 0.8236, Self-BLEU-[2, 3, 4] = 0, [PPL-F, PPL-R] = 0
